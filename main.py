import vosk
import pyaudio
import json
import os
import torch
import pygame
import threading
import queue
import re
import numpy as np
from TTS.api import TTS
from TTS.tts.configs.xtts_config import XttsConfig
from TTS.tts.models.xtts import XttsAudioConfig, XttsArgs
from TTS.config.shared_configs import BaseDatasetConfig
from langchain_core.messages import HumanMessage
from agent.main import request_to_agent

WAKE_WORD = "–¥–∂–∞—Ä–≤–∏—Å"
MODEL_FOLDER_NAME = "vosk-model-small-ru-0.22"
WAITING_SOUND = "4115442.mp3"
XTTS_SR = 24000
INPUT_SAMPLE_RATE = 16000
INPUT_FRAMES_PER_BUFFER = 4096
COMMAND_TIMEOUT_SECONDS = 10
FOLLOW_UP_TIMEOUT_SECONDS = 8 # –í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–π –∫–æ–º–∞–Ω–¥—ã

chat_history = []

pygame.mixer.init()
activate_sound = pygame.mixer.Sound(WAITING_SOUND)

if not os.path.exists(MODEL_FOLDER_NAME):
    print(f"–û—à–∏–±–∫–∞: –ü–∞–ø–∫–∞ —Å –º–æ–¥–µ–ª—å—é '{MODEL_FOLDER_NAME}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
    exit()

vosk_model = vosk.Model(MODEL_FOLDER_NAME)
vosk_recognizer = vosk.KaldiRecognizer(vosk_model, INPUT_SAMPLE_RATE)
vosk_recognizer.SetWords(True)

print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ TTS...")
device = "cuda" if torch.cuda.is_available() else "cpu"
torch.serialization.add_safe_globals([XttsConfig, XttsAudioConfig, BaseDatasetConfig, XttsArgs])
try:
    coqui_tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)
    print(f"–ú–æ–¥–µ–ª—å TTS —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ {device.upper()}.")
except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏ TTS: {e}")
    exit()

pa = pyaudio.PyAudio()
stream = pa.open(
    format=pyaudio.paInt16,
    channels=1,
    rate=INPUT_SAMPLE_RATE,
    input=True,
    frames_per_buffer=INPUT_FRAMES_PER_BUFFER
)


def sentence_chunks(text):
    pat = re.compile(r'[^\.!\?‚Ä¶]+[\.!\?‚Ä¶]+(?:["¬ª)]?)(?:\s*)', re.DOTALL)
    pos = 0
    for m in pat.finditer(text):
        yield m.group(0)
        pos = m.end()
    if pos < len(text):
        yield text[pos:]


def speak_streaming(text, speaker_wav="test2.mp3", language="ru", speed=5.0, volume=0.5):
    q = queue.Queue(maxsize=64)

    def producer():
        with torch.no_grad():
            for sent in sentence_chunks(text):
                try:
                    for wav_chunk in coqui_tts.tts_stream(text=sent, speaker_wav=speaker_wav, language=language, speed=speed):
                        wav_chunk = np.asarray(wav_chunk, dtype=np.float32).flatten()
                        wav_chunk = (wav_chunk * volume).clip(-1.0, 1.0)
                        pcm16 = (wav_chunk * 32767.0).astype(np.int16).tobytes()
                        q.put(pcm16)
                except Exception:
                    wav = coqui_tts.tts(text=sent, speaker_wav=speaker_wav, language=language, speed=speed)
                    wav = np.asarray(wav, dtype=np.float32).flatten()
                    wav = (wav * volume).clip(-1.0, 1.0)
                    pcm16 = (wav * 32767.0).astype(np.int16).tobytes()
                    q.put(pcm16)
        q.put(None)

    def consumer():
        out = pa.open(format=pyaudio.paInt16, channels=1, rate=XTTS_SR, output=True, frames_per_buffer=1024)
        try:
            while True:
                data = q.get()
                if data is None:
                    break
                out.write(data)
        finally:
            out.stop_stream()
            out.close()

    t_prod = threading.Thread(target=producer, daemon=True)
    t_cons = threading.Thread(target=consumer, daemon=True)
    t_cons.start()
    t_prod.start()
    t_prod.join()
    t_cons.join()


def listen_for_command_vosk(audio_stream, recognizer, timeout_seconds):
    activate_sound.play()
    print(f"–°–ª—É—à–∞—é –∫–æ–º–∞–Ω–¥—É ({timeout_seconds} —Å–µ–∫)...")
    max_chunks = int((INPUT_SAMPLE_RATE / INPUT_FRAMES_PER_BUFFER) * timeout_seconds)
    
    for i in range(max_chunks):
        data = audio_stream.read(INPUT_FRAMES_PER_BUFFER, exception_on_overflow=False)
        if recognizer.AcceptWaveform(data):
            result_json = recognizer.FinalResult()
            result_dict = json.loads(result_json)
            command = result_dict.get("text", "")
            if command:
                return command.strip()
    
    return "–≤—Ä–µ–º—è –≤—ã—à–ª–æ"

stream.start_stream()
print(f"\n‚úÖ –°–∏—Å—Ç–µ–º–∞ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–∞. –û–∂–∏–¥–∞–Ω–∏–µ –∫–æ–¥–æ–≤–æ–≥–æ —Å–ª–æ–≤–∞ '{WAKE_WORD}'...")

try:
    while True:
        data = stream.read(INPUT_FRAMES_PER_BUFFER, exception_on_overflow=False)

        if vosk_recognizer.AcceptWaveform(data):
            result_json = vosk_recognizer.Result()
            result_dict = json.loads(result_json)
            text = result_dict.get("text", "")

            if WAKE_WORD in text:
                print(f"‚ñ∂Ô∏è –ö–æ–¥–æ–≤–æ–µ —Å–ª–æ–≤–æ '{WAKE_WORD}' –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ!")
                
                command = text.replace(WAKE_WORD, "").strip()

                if not command:
                    command = listen_for_command_vosk(stream, vosk_recognizer, COMMAND_TIMEOUT_SECONDS)
                else:
                    activate_sound.play()

                # –ù–∞—á–∞–ª–æ —Ü–∏–∫–ª–∞ –¥–∏–∞–ª–æ–≥–∞
                while command and "–≤—Ä–µ–º—è –≤—ã—à–ª–æ" not in command:
                    print(f"–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞: '{command}'")

                    chat_history.append(HumanMessage(content=command))
                    response_history = request_to_agent(chat_history)
                    
                    if response_history:
                        chat_history = response_history
                        response_text = response_history[-1].content
                    else:
                        response_text = "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞."

                    if response_text:
                        print(f"–û—Ç–≤–µ—Ç –∞–≥–µ–Ω—Ç–∞: {response_text}")
                        speak_streaming(response_text, speaker_wav="test.wav", language="ru", speed=5.0, volume=0.5)
                    else:
                        print("–ê–≥–µ–Ω—Ç –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç.")
                    
                    # –û–∂–∏–¥–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–π –∫–æ–º–∞–Ω–¥—ã
                    command = listen_for_command_vosk(stream, vosk_recognizer, FOLLOW_UP_TIMEOUT_SECONDS)

                # –ï—Å–ª–∏ —Ü–∏–∫–ª –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –∏–∑-–∑–∞ —Ç–∞–π–º-–∞—É—Ç–∞ –∏–ª–∏ –ø—É—Å—Ç–æ–π –∫–æ–º–∞–Ω–¥—ã
                if "–≤—Ä–µ–º—è –≤—ã—à–ª–æ" in command:
                    print("–í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–π –∫–æ–º–∞–Ω–¥—ã –∏—Å—Ç–µ–∫–ª–æ.")
                else:
                    print(f"–ö–æ–º–∞–Ω–¥—É –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å. ({command})")

                print(f"\nüîÅ –°–Ω–æ–≤–∞ –∂–¥—É –∫–æ–¥–æ–≤–æ–µ —Å–ª–æ–≤–æ '{WAKE_WORD}'...")
                vosk_recognizer.Reset()

except KeyboardInterrupt:
    print("\n–ü—Ä–æ–≥—Ä–∞–º–º–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")

finally:
    print("–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")
    if stream.is_active():
        stream.stop_stream()
        stream.close()
    pa.terminate()